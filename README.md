# Monografia_especializacion

ğŸ“˜ PredicciÃ³n del Precio de la AcciÃ³n del Grupo Bancolombia usando RNN, LSTM, GRU y AnÃ¡lisis de Sentimiento

Este repositorio contiene un proyecto de predicciÃ³n del precio de apertura de la acciÃ³n de Bancolombia en la bolsa de New York (CIB) utilizando diferentes arquitecturas de redes neuronales recurrentes (RNN): RNN Simple, GRU, LSTM, y versiones de estos modelos que incorporan una variable de sentimiento generada a partir del anÃ¡lisis de noticias.

El enfoque es multivariante, integrando variables econÃ³micas y una variable binaria que representa el sentimiento (1 = positivo, 0 = negativo).

ğŸ“ Estructura del Proyecto
ğŸ“‚ /
â”œâ”€â”€ baseline.ipynb
â”œâ”€â”€ modelo_solo_rnn.ipynb
â”œâ”€â”€ modelo_solo_gru.ipynb
â”œâ”€â”€ modelo_solo_lstm.ipynb
â””â”€â”€ modelo_sentimiento.ipynb

Notebook	DescripciÃ³n
baseline.ipynb	Modelo baseline utilizado como referencia.
modelo_solo_rnn.ipynb	Modelo basado en Simple RNN sin la variable de sentimiento.
modelo_solo_gru.ipynb	Modelo GRU sin la variable de sentimiento.
modelo_solo_lstm.ipynb	Modelo LSTM sin la variable de sentimiento.
modelo_sentimiento.ipynb	Versiones RNN, GRU y LSTM incluyendo la variable de sentimiento.
ğŸ§  Modelos Implementados
ğŸ”¹ Baseline

Modelo simple utilizado para establecer un punto mÃ­nimo de comparaciÃ³n.

ğŸ”¹ Modelos sin Sentimiento

Se entrenaron tres modelos independientes:

RNN Simple

GRU

LSTM

Cada uno predice el precio sin usar la variable de sentimiento.

ğŸ”¹ Modelos con Sentimiento

En modelo_sentimiento.ipynb se entrenan nuevamente los modelos:

RNN + sentimiento

GRU + sentimiento

LSTM + sentimiento

La variable de sentimiento se define como:

sentimiento âˆˆ {0, 1}

ğŸ›  MetodologÃ­a

Escalado con MinMaxScaler.

ConstrucciÃ³n de ventanas temporales para series de tiempo.

DivisiÃ³n en datos de entrenamiento y prueba.

Entrenamiento con Adam + MSE.

AplicaciÃ³n de EarlyStopping.

EvaluaciÃ³n con MAE y RMSE.

GrÃ¡ficas comparativas entre valores reales y predichos.

ğŸ“Š MÃ©tricas
MAE â€” Mean Absolute Error
\[
MAE = \frac{1}{N} \sum_{i=1}^{N} \left| \hat{y}_i - y_i \right|
\]

RMSE â€” Root Mean Squared Error
\[
RMSE = \sqrt{ \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2 }
\]

ğŸ“ˆ Visualizaciones

Los notebooks generan:

GrÃ¡fica de pÃ©rdida vs. Ã©pocas

ComparaciÃ³n entre precio real y predicho

Resultados por arquitectura

ComparaciÃ³n con y sin sentimiento

âœ… Conclusiones Generales

LSTM fue la arquitectura mÃ¡s precisa.

GRU logrÃ³ un rendimiento muy cercano con menor costo computacional.

RNN simple mostrÃ³ limitaciones frente a GRU/LSTM.

La variable de sentimiento mejora el desempeÃ±o, especialmente en GRU y LSTM.

Todos los modelos avanzados superan al baseline.

â–¶ï¸ CÃ³mo Ejecutar el Proyecto
Instalar dependencias:
pip install tensorflow pandas numpy matplotlib scikit-learn

Ejecutar los notebooks:
jupyter notebook modelo_solo_lstm.ipynb
