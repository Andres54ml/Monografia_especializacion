# Monografia_especializacion

ğŸ“˜ PredicciÃ³n del Precio de la AcciÃ³n del Grupo Bancolombia usando RNN, LSTM, GRU y AnÃ¡lisis de Sentimiento

Este repositorio contiene un proyecto de predicciÃ³n del precio de apertura de la acciÃ³n de Bancolombia en la bolsa de New York (CIB) utilizando diferentes arquitecturas de redes neuronales recurrentes (RNN): RNN Simple, GRU, LSTM, y versiones de estos modelos que incorporan una variable de sentimiento generada a partir del anÃ¡lisis de noticias.

El enfoque es multivariante, integrando variables econÃ³micas y una variable binaria que representa el sentimiento (1 = positivo, 0 = negativo).

ğŸ“ Estructura del Proyecto
ğŸ“‚ /
â”œâ”€â”€ baseline.ipynb
â”œâ”€â”€ modelo_solo_rnn.ipynb
â”œâ”€â”€ modelo_solo_gru.ipynb
â”œâ”€â”€ modelo_solo_lstm.ipynb
â””â”€â”€ modelo_sentimiento.ipynb

Notebook	DescripciÃ³n
baseline.ipynb	Modelo baseline utilizado como referencia.
modelo_solo_rnn.ipynb	Modelo basado en Simple RNN sin la variable de sentimiento.
modelo_solo_gru.ipynb	Modelo GRU sin la variable de sentimiento.
modelo_solo_lstm.ipynb	Modelo LSTM sin la variable de sentimiento.
modelo_sentimiento.ipynb	Versiones RNN, GRU y LSTM incluyendo la variable de sentimiento.
ğŸ§  Modelos Implementados
ğŸ”¹ Baseline

Modelo simple utilizado para establecer un punto mÃ­nimo de comparaciÃ³n.

ğŸ”¹ Modelos sin Sentimiento

Se entrenaron tres modelos independientes:

RNN Simple

GRU

LSTM

Cada uno predice el precio sin usar la variable de sentimiento.

ğŸ”¹ Modelos con Sentimiento

En modelo_sentimiento.ipynb se entrenan nuevamente los modelos:

RNN + sentimiento

GRU + sentimiento

LSTM + sentimiento

La variable de sentimiento se define como:

sentimiento âˆˆ {0, 1}

ğŸ›  MetodologÃ­a

Escalado con MinMaxScaler.

ConstrucciÃ³n de ventanas temporales para series de tiempo.

DivisiÃ³n en datos de entrenamiento y prueba.

Entrenamiento con Adam + MSE.

AplicaciÃ³n de EarlyStopping.

EvaluaciÃ³n con MAE y RMSE.

GrÃ¡ficas comparativas entre valores reales y predichos.

ğŸ“Š MÃ©tricas
MAE â€” Mean Absolute Error
\[
MAE = \frac{1}{N} \sum_{i=1}^{N} \left| \hat{y}_i - y_i \right|
\]

RMSE â€” Root Mean Squared Error
\[
RMSE = \sqrt{ \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2 }
\]

ğŸ“ˆ Visualizaciones

Los notebooks generan:

GrÃ¡fica de pÃ©rdida vs. Ã©pocas

ComparaciÃ³n entre precio real y predicho

Resultados por arquitectura

ComparaciÃ³n con y sin sentimiento

âœ… Conclusiones Generales

LSTM fue la arquitectura mÃ¡s precisa.

GRU logrÃ³ un rendimiento muy cercano con menor costo computacional.

RNN simple mostrÃ³ limitaciones frente a GRU/LSTM.

La variable de sentimiento mejora el desempeÃ±o, especialmente en GRU y LSTM.

Todos los modelos avanzados superan al baseline.

â–¶ï¸ CÃ³mo Ejecutar el Proyecto
Instalar dependencias:
pip install tensorflow pandas numpy matplotlib scikit-learn

Ejecutar los notebooks:
jupyter notebook modelo_solo_lstm.ipynb

































ğŸ“˜ MonografÃ­a â€“ EspecializaciÃ³n
PredicciÃ³n del Precio de la AcciÃ³n del Grupo Bancolombia usando RNN, LSTM, GRU y AnÃ¡lisis de Sentimiento

Este repositorio contiene un proyecto de predicciÃ³n del precio de apertura de la acciÃ³n de Bancolombia en la bolsa de New York (CIB) utilizando diferentes arquitecturas de redes neuronales recurrentes: Simple RNN, GRU, LSTM, ademÃ¡s de modelos que integran una variable de sentimiento generada mediante anÃ¡lisis de noticias.

El enfoque es multivariante, integrando variables econÃ³micas y una variable binaria de sentimiento:

1 = positivo

0 = negativo

ğŸ“ Estructura del Proyecto
/ 
â”œâ”€â”€ baseline.ipynb
â”œâ”€â”€ modelo_solo_rnn.ipynb
â”œâ”€â”€ modelo_solo_gru.ipynb
â”œâ”€â”€ modelo_solo_lstm.ipynb
â”œâ”€â”€ modelo_sentimiento.ipynb
â”œâ”€â”€ construccion_sentimiento/
â”‚     â””â”€â”€ (scripts y notebooks para anÃ¡lisis y clasificaciÃ³n de sentimiento)
â””â”€â”€ preprocesamiento_imagen/
      â””â”€â”€ (imÃ¡genes, grÃ¡ficas o recursos usados para el informe)

ğŸ“„ DescripciÃ³n de Notebooks
Notebook	DescripciÃ³n
baseline.ipynb	Modelo base utilizado como referencia inicial.
modelo_solo_rnn.ipynb	ImplementaciÃ³n de una Simple RNN sin variable de sentimiento.
modelo_solo_gru.ipynb	ImplementaciÃ³n de una GRU sin la variable de sentimiento.
modelo_solo_lstm.ipynb	ImplementaciÃ³n de una LSTM sin la variable de sentimiento.
modelo_sentimiento.ipynb	Versiones RNN, GRU y LSTM incluyendo la variable binaria de sentimiento.
Carpetas nuevas
Carpeta	DescripciÃ³n
construccion_sentimiento/	Contiene el proceso de scraping, limpieza, anÃ¡lisis y clasificaciÃ³n de sentimiento usado para generar la variable binaria.
preprocesamiento_imagen/	Almacena recursos visuales utilizados en el proyecto (grÃ¡ficas, imÃ¡genes para la monografÃ­a, ejemplos, etc.).
ğŸ§  Modelos Implementados
ğŸ”¹ Baseline

Modelo simple para establecer un punto mÃ­nimo de comparaciÃ³n.

ğŸ”¹ Modelos sin Sentimiento

Tres modelos independientes:

Simple RNN

GRU

LSTM

ğŸ”¹ Modelos con Sentimiento

Entrenados en modelo_sentimiento.ipynb:

RNN + sentimiento

GRU + sentimiento

LSTM + sentimiento

La variable utilizada es binaria:
sentimiento âˆˆ {0, 1}

ğŸ›  MetodologÃ­a

Escalado con MinMaxScaler

ConstrucciÃ³n de ventanas temporales

DivisiÃ³n en train / test

Entrenamiento con Adam y pÃ©rdida MSE

AplicaciÃ³n de EarlyStopping

MÃ©tricas: MAE y RMSE

GrÃ¡ficas comparativas entre real vs. predicho

ğŸ“Š MÃ©tricas
MAE â€” Mean Absolute Error
ğ‘€
ğ´
ğ¸
=
1
ğ‘
âˆ‘
ğ‘–
=
1
ğ‘
âˆ£
ğ‘¦
^
ğ‘–
âˆ’
ğ‘¦
ğ‘–
âˆ£
MAE=
N
1
	â€‹

i=1
âˆ‘
N
	â€‹

âˆ£
y
^
	â€‹

i
	â€‹

âˆ’y
i
	â€‹

âˆ£
RMSE â€” Root Mean Squared Error
ğ‘…
ğ‘€
ğ‘†
ğ¸
=
1
ğ‘
âˆ‘
ğ‘–
=
1
ğ‘
(
ğ‘¦
^
ğ‘–
âˆ’
ğ‘¦
ğ‘–
)
2
RMSE=
N
1
	â€‹

i=1
âˆ‘
N
	â€‹

(
y
^
	â€‹

i
	â€‹

âˆ’y
i
	â€‹

)
2
	â€‹

ğŸ“ˆ Visualizaciones Generadas

GrÃ¡fica de pÃ©rdida vs Ã©pocas

ComparaciÃ³n precio real vs predicho

ComparaciÃ³n entre modelos

ComparaciÃ³n con y sin sentimiento

âœ… Conclusiones Generales

LSTM fue la arquitectura mÃ¡s precisa.

GRU obtuvo resultados muy cercanos con menor costo computacional.

RNN simple mostrÃ³ limitaciones frente a GRU y LSTM.

La variable de sentimiento mejora el desempeÃ±o, especialmente en GRU y LSTM.

Todos los modelos avanzados superan al baseline.

â–¶ï¸ CÃ³mo Ejecutar el Proyecto
1. Instalar dependencias
pip install tensorflow pandas numpy matplotlib scikit-learn

2. Ejecutar los notebooks
jupyter notebook modelo_solo_lstm.ipynb

